{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nealshiyekar/Deepfake-Detectoin/blob/main/GradioApp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIG-b6yc7WBL",
        "outputId": "9fff14a8-2ace-43af-f795-422186910389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.28.3-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.0 (from gradio)\n",
            "  Downloading gradio_client-0.16.0-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.4/314.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m801.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=89f0a491e3cb28f5652f12655546725e51b841490ae827a9cac2a6b01ea36517\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio\n",
        "!pip install torch\n",
        "!pip install facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heGJimhSa9dJ"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import csv\n",
        "import pandas as pd\n",
        "import torch\n",
        "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import v2\n",
        "import torchvision.io as io\n",
        "from torchvision.io import read_image\n",
        "import math\n",
        "import os\n",
        "import pickle\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "IMAGE_SIZE = 112"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v44hysGfyLZ"
      },
      "outputs": [],
      "source": [
        "def CaptureFrames(vid_path, imageset):\n",
        "  if os.path.exists(\"/content/\"+ imageset +\"/extracted\") == True:\n",
        "    shutil.rmtree(\"/content/\" + imageset + \"/extracted\")\n",
        "\n",
        "  output_folder = os.mkdir(\"/content/\" + imageset + \"/extracted\")\n",
        "\n",
        "\n",
        "  video_path = vid_path\n",
        "  vidcap = cv2.VideoCapture(video_path)\n",
        "  success, image = vidcap.read()\n",
        "\n",
        "  if success == False:\n",
        "    print(\"cound not read video frame\")\n",
        "\n",
        "\n",
        "    #Gets number of frames in the video\n",
        "  num_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  print(video_path + ' has ' + str(num_frames) + ' frames')\n",
        "\n",
        "  next_frame = random.randrange(num_frames - 50)\n",
        "\n",
        "  for i in range(50):\n",
        "    #It's possible for the same random number to be generated, but because each video has hundreds of\n",
        "    #frames, this is too uncommon to have a noticeable impact\n",
        "\n",
        "    next_frame_str = str(next_frame).zfill(5)\n",
        "    #If next_frame is an integer that is less than 5 digits long, this fills digits to the left with 0s\n",
        "\n",
        "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, next_frame)\n",
        "    success, image = vidcap.read()\n",
        "\n",
        "    image_name = \"/content/\" + imageset + \"/extracted/\" + f\"poss_deepfake_frame{next_frame_str}.jpg\"\n",
        "    #Every filename has the format \"Youtube-real_idABCDE_frameFGHIJ.jpg\"\n",
        "\n",
        "    cv2.imwrite(image_name, image)\n",
        "    next_frame = next_frame + 1\n",
        "    print(image_name)\n",
        "\n",
        "# 'poss_deepfake_vid_frames' , or 'realimage'\n",
        "\n",
        "def cropPredFrames(imageset):\n",
        "  # crop\n",
        "  # If required, create a face detection pipeline using MTCNN:\n",
        "  mtcnn = MTCNN(image_size=IMAGE_SIZE, margin=35)\n",
        "\n",
        "  # Create an inception resnet (in eval mode):\n",
        "  resnet = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "\n",
        "  if os.path.exists(\"/content/\" + imageset + \"/CroppedFrames\") == True:\n",
        "    shutil.rmtree(\"/content/\" + imageset + \"/CroppedFrames\")\n",
        "\n",
        "  os.mkdir(\"/content/\" + imageset + \"/CroppedFrames\")\n",
        "\n",
        "  list_frames = os.listdir(\"/content/\" + imageset + \"/extracted\")\n",
        "  list_frames = sorted(list_frames)\n",
        "\n",
        "  for frame in list_frames:\n",
        "    image = Image.open(\"/content/\" + imageset + \"/extracted/\" + frame)\n",
        "\n",
        "    print(frame)\n",
        "\n",
        "    # Get cropped and prewhitened image tensor\n",
        "    image_cropped = mtcnn(image, save_path=\"/content/\" + imageset + \"/CroppedFrames/\" + frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvUwyPGNf6QB"
      },
      "outputs": [],
      "source": [
        "def getFinalEmbeddings(imageset):\n",
        "  if os.path.exists(\"/content/\" + imageset + \"/Embeddings\") == True:\n",
        "    shutil.rmtree(\"/content/\" + imageset + \"/Embeddings\")\n",
        "\n",
        "  embeddings_dict = {}\n",
        "  # embeddings_folder = os.mkdir(\"/content/\" + imageset + \"Outputs/\" + imageset + \"Embeddings\")\n",
        "\n",
        "  #model = GhostFaceNetsV2(image_size=IMAGE_SIZE, width=1, dropout=0.)\n",
        "  #model = GhostFaceNetsV2(image_size=IMAGE_SIZE, num_classes=3, width=1, dropout=0.)\n",
        "  #model = GhostFaceNetsV2(image_size=IMAGE_SIZE, num_classes=0, width=1, dropout=0.)\n",
        "  #model = GhostFaceNetsV2(image_size=IMAGE_SIZE, width=1, dropout=0.)\n",
        "\n",
        "  model = InceptionResnetV1(pretrained='vggface2')\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  #list_frames = os.listdir(\"/content/\" + imageset + \"Outputs/\" + imageset + \"Frames\")\n",
        "  list_frames = os.listdir(\"/content/\" + imageset + \"/CroppedFrames\")\n",
        "  list_frames = sorted(list_frames)\n",
        "\n",
        "\n",
        "  for frame in list_frames:\n",
        "    #image = Image.open(\"/content/\" + imageset + \"Outputs/\" + imageset + \"Frames/\" + frame)\n",
        "    image = Image.open(\"/content/\" + imageset + \"/CroppedFrames/\" + frame)\n",
        "    transform = v2.Compose([v2.ToImage(), v2.Resize((IMAGE_SIZE, IMAGE_SIZE))])\n",
        "\n",
        "    img_tensor = transform(image)\n",
        "    img_tensor = img_tensor.float()\n",
        "    img_tensor = img_tensor.unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      embedding = model(img_tensor)\n",
        "      embeddings_dict[frame] = embedding\n",
        "\n",
        "\n",
        "\n",
        "      #print(embedding)\n",
        "      #print(embedding.shape)\n",
        "\n",
        "  #for frame, embedding in embeddings_dict.items():\n",
        "  #  print(f\"Frame: {frame}, Embedding: {embedding}\")\n",
        "\n",
        "  return embeddings_dict, list_frames\n",
        "\n",
        "  # with open(\"/content/\" + imageset + \"Outputs/\" + imageset + \"Embeddings/\" + imageset + \"Embeddings.csv\", \"w\", newline=\"\") as csvFile:\n",
        "  #   writer = csv.writer(csvFile)\n",
        "  #   #writer.writerow([\"Frame\", \"Embedding\"])\n",
        "  #   writer.writerow([\"CroppedFrame\", \"Embedding\"])\n",
        "  #   for frame, embedding in embeddings_dict.items():\n",
        "  #     writer.writerow([frame, \",\".join(map(str, embedding))])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOm69zdxbghE"
      },
      "outputs": [],
      "source": [
        "def deepfakeImgImgPred(poss_deepfake, img_real):\n",
        "  if os.path.exists(\"/content/realimage/extracted\") == True:\n",
        "    shutil.rmtree(\"/content/realimage/extracted\")\n",
        "  output_folder = os.mkdir(\"/content/realimage/extracted\")\n",
        "  real_img = Image.open(img_real)\n",
        "  real_img = real_img.save(\"/content/realimage/extracted/img_real.jpg\")\n",
        "  poss_deepfake = Image.open(poss_deepfake)\n",
        "  poss_deepfake = poss_deepfake.save(\"/content/realimage/extracted/poss_deepfake.jpg\")\n",
        "  cropPredFrames(\"realimage\")\n",
        "  # embeddings of each image\n",
        "  imgEmbedding, frames = getFinalEmbeddings(\"realimage\")\n",
        "  #euclidean distance\n",
        "  #torch.cdist(x1, x2, p=2.0, compute_mode='use_mm_for_euclid_dist_if_necessary')\n",
        "  edist = torch.cdist(imgEmbedding[frames[0]],imgEmbedding[frames[1]],2.0)\n",
        "  edist.shape\n",
        "  print(edist.item())\n",
        "  return str(edist.item())\n",
        "def deepfakeVidImgPred(poss_deepfake, img_real):\n",
        "  # capture frames from video\n",
        "  # crop video frames and image\n",
        "  # get embeddings for video frames and image\n",
        "  # average video frame embeddings\n",
        "  # euclidean distance between vid embeddings and image\n",
        "  # give pred based on threshold\n",
        "  if os.path.exists(\"/content/poss_deepfake_vid_frames\") == True:\n",
        "    shutil.rmtree(\"/content/poss_deepfake_vid_frames\")\n",
        "  folder = os.mkdir(\"/content/poss_deepfake_vid_frames\")\n",
        "\n",
        "  if os.path.exists(\"/content/poss_deepfake_vid_frames/extracted\") == True:\n",
        "    shutil.rmtree(\"/content/poss_deepfake_vid_frames/extracted\")\n",
        "  output_folder = os.mkdir(\"/content/poss_deepfake_vid_frames/extracted\")\n",
        "\n",
        "  CaptureFrames(poss_deepfake, \"poss_deepfake_vid_frames\")\n",
        "  if os.path.exists(\"/content/realimage/extracted\") == True:\n",
        "    shutil.rmtree(\"/content/realimage/extracted\")\n",
        "  output_folder = os.mkdir(\"/content/realimage/extracted\")\n",
        "  real_img = Image.open(img_real)\n",
        "  real_img = real_img.save(\"/content/realimage/extracted/img_real.jpg\")\n",
        "  cropPredFrames(\"poss_deepfake_vid_frames\")\n",
        "  cropPredFrames(\"realimage\")\n",
        "  vidEmbeddings,_ = getFinalEmbeddings(\"poss_deepfake_vid_frames\")\n",
        "  imgEmbedding,frames = getFinalEmbeddings(\"realimage\")\n",
        "  sum = torch.zeros(1, 512)\n",
        "  for embedding in vidEmbeddings:\n",
        "    sum = sum + vidEmbeddings[embedding]\n",
        "  avg_vid_embedding = sum / 50\n",
        "  edist = torch.cdist(imgEmbedding[frames[0]],avg_vid_embedding,2.0)\n",
        "  print(edist)\n",
        "  return str(edist.item())\n",
        "\n",
        "def deepfakeVidVidPred(poss_deepfake, vid_real):\n",
        "  if os.path.exists(\"/content/poss_deepfake_vid_frames\") == True:\n",
        "    shutil.rmtree(\"/content/poss_deepfake_vid_frames\")\n",
        "  folder = os.mkdir(\"/content/poss_deepfake_vid_frames\")\n",
        "\n",
        "  if os.path.exists(\"/content/realimage\") == True:\n",
        "    shutil.rmtree(\"/content/realimage\")\n",
        "  folder = os.mkdir(\"/content/realimage\")\n",
        "\n",
        "  if os.path.exists(\"/content/poss_deepfake_vid_frames/extracted\") == True:\n",
        "    shutil.rmtree(\"/content/poss_deepfake_vid_frames/extracted\")\n",
        "  output_folder = os.mkdir(\"/content/poss_deepfake_vid_frames/extracted\")\n",
        "\n",
        "  if os.path.exists(\"/content/realimage/extracted\") == True:\n",
        "    shutil.rmtree(\"/content/realimage/extracted\")\n",
        "  output_folder = os.mkdir(\"/content/realimage/extracted\")\n",
        "  CaptureFrames(poss_deepfake, \"poss_deepfake_vid_frames\")\n",
        "  CaptureFrames(vid_real, \"realimage\")\n",
        "  cropPredFrames(\"poss_deepfake_vid_frames\")\n",
        "  cropPredFrames(\"realimage\")\n",
        "  possdfvidEmbeddings,_ = getFinalEmbeddings(\"poss_deepfake_vid_frames\")\n",
        "  realvidEmbeddings,_ = getFinalEmbeddings(\"realimage\")\n",
        "  sum = torch.zeros(1, 512)\n",
        "  for embedding in possdfvidEmbeddings:\n",
        "    sum = sum + possdfvidEmbeddings[embedding]\n",
        "  avg_dfvid_embedding = sum / 50\n",
        "  realsum = torch.zeros(1, 512)\n",
        "  for embedding in realvidEmbeddings:\n",
        "    realsum = realsum + realvidEmbeddings[embedding]\n",
        "  avg_real_embedding = realsum / 50\n",
        "  edist = torch.cdist(avg_dfvid_embedding,avg_real_embedding,2.0)\n",
        "  print(edist)\n",
        "  return str(edist.item())\n",
        "\n",
        "def deepfakePredHelper(input_type, poss_deepfake, img_real, input_format):\n",
        "\n",
        "  if os.path.exists(\"/content/realimage\") == True:\n",
        "    shutil.rmtree(\"/content/realimage\")\n",
        "  folder = os.mkdir(\"/content/realimage\")\n",
        "\n",
        "\n",
        "  if input_type == \"Image/Image\":\n",
        "    pred = deepfakeImgImgPred(poss_deepfake, img_real)\n",
        "  if input_format == \"Video/Image\":\n",
        "    pred = deepfakeVidImgPred(poss_deepfake, img_real)\n",
        "  if input_format == \"Image/Video\":\n",
        "    pred = deepfakeVidImgPred(img_real, poss_deepfake)\n",
        "  if input_format == \"Video/Video\":\n",
        "    pred = deepfakeVidVidPred(poss_deepfake, img_real)\n",
        "  return pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZD-ri1EFiHB",
        "outputId": "84acdd3e-c68c-42b4-f353-1a89d66961b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-05-02 02:17:57--  https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_linux_amd64\n",
            "Resolving cdn-media.huggingface.co (cdn-media.huggingface.co)... 13.33.21.15, 13.33.21.96, 13.33.21.8, ...\n",
            "Connecting to cdn-media.huggingface.co (cdn-media.huggingface.co)|13.33.21.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11374592 (11M) [binary/octet-stream]\n",
            "Saving to: ‘frpc_linux_amd64.1’\n",
            "\n",
            "\rfrpc_linux_amd64.1    0%[                    ]       0  --.-KB/s               \rfrpc_linux_amd64.1  100%[===================>]  10.85M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-05-02 02:17:57 (135 MB/s) - ‘frpc_linux_amd64.1’ saved [11374592/11374592]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://cdn-media.huggingface.co/frpc-gradio-0.2/frpc_linux_amd64\n",
        "!cp '/content/frpc_linux_amd64' '/usr/local/lib/python3.10/dist-packages/gradio'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hG75jhl77rFY",
        "outputId": "a36deb66-114b-4c04-c39d-7233039b14ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:953: UserWarning: Expected 4 arguments for function <function deepfakePredHelper at 0x7d9349c49bd0>, received 3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:957: UserWarning: Expected at least 4 arguments for function <function deepfakePredHelper at 0x7d9349c49bd0>, received 3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://6c87bc082110f438d7.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://6c87bc082110f438d7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/helpers.py:946: UserWarning: Unexpected argument. Filling with None.\n",
            "  warnings.warn(\"Unexpected argument. Filling with None.\")\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 650, in _save\n",
            "    rawmode = RAWMODE[im.mode]\n",
            "KeyError: 'RGBA'\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 527, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 270, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1847, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1433, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 788, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-13-1fce69c3e132>\", line 93, in deepfakePredHelper\n",
            "    pred = deepfakeImgImgPred(poss_deepfake, img_real)\n",
            "  File \"<ipython-input-13-1fce69c3e132>\", line 6, in deepfakeImgImgPred\n",
            "    real_img = real_img.save(\"/content/realimage/extracted/img_real.jpg\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2439, in save\n",
            "    save_handler(self, fp, filename)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/JpegImagePlugin.py\", line 653, in _save\n",
            "    raise OSError(msg) from e\n",
            "OSError: cannot write mode RGBA as JPEG\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "# put the overall function here\n",
        "def predict(input_type, real, possible_deepfake):\n",
        "  if input_type == \"Image/Image\" or input_type == \"Image/Video\":\n",
        "        return \"real\"\n",
        "  elif input_type == \"Video/Image\" or input_type == \"Video/Video\":\n",
        "        return \"fake\"\n",
        "  return \"real\"\n",
        "\n",
        "inputs = [\n",
        "    gr.Dropdown(choices=[\"Image/Image\", \"Video/Image\", \"Image/Video\", \"Video/Video\"], label=\"Input Type\", info=\"Choose type of inputs\"),\n",
        "    \"file\",\n",
        "    \"file\"\n",
        "]\n",
        "outputs = [\"textbox\"]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=deepfakePredHelper,\n",
        "    inputs = inputs,\n",
        "    outputs= outputs,\n",
        "    title=\"Deepfake Detection\",\n",
        "    description=\"Upload images or videos to determine if it's real or fake.\",\n",
        "    theme=\"soft\",\n",
        "    #live=True,\n",
        "    allow_flagging=\"never\",\n",
        "\n",
        "\n",
        "    css = \"\"\"\n",
        "          .gradio-interface {\n",
        "          font-family: Arial, sans-serif;\n",
        "          background-color: #f0f0f0; /* Updated background color */\n",
        "          padding: 20px; /* Added padding for spacing */\n",
        "      }\n",
        "\n",
        "      .gradio-input, .gradio-output {\n",
        "          border-radius: 10px;\n",
        "          box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1);\n",
        "          margin-bottom: 20px;\n",
        "          background-color: #ffffff;\n",
        "          padding: 20px; /* Added padding for spacing */\n",
        "      }\n",
        "\n",
        "      .gradio-input-title, .gradio-output-title {\n",
        "          font-size: 20px;\n",
        "          font-weight: bold;\n",
        "          color: #333333;\n",
        "          margin-bottom: 10px; /* Added margin for spacing */.\n",
        "      }\n",
        "\n",
        "      .output_textbox textarea {\n",
        "          width: 100%;\n",
        "          height: 150px;\n",
        "          padding: 10px;\n",
        "          border-radius: 5px;\n",
        "          border: 1px solid #ced4da;\n",
        "          font-size: 16px;\n",
        "          resize: vertical;\n",
        "      }\n",
        "\n",
        "      .output_textbox label {\n",
        "          display: block;\n",
        "          margin-bottom: 5px;\n",
        "      }\n",
        "      \"\"\"\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}